{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Author: NJ Namju Lee / nj.namju@gmail.com  \n",
    "###### * Linkedin - https://www.linkedin.com/in/nj-namju-lee-926b3252/    * Git - https://github.com/NamjuLee  \n",
    "\n",
    "###### * Web - http://www.njstudio.co.kr                                  * Lab - http://www.njslab.com/NJSLabCore/  \n",
    "\n",
    "###### * Video(English) - https://www.youtube.com/c/njnamjulee            * Writing(English) - https://medium.com/@nj-namju  \n",
    "\n",
    "###### * Video(Korean) - https://www.youtube.com/c/CodeforDesign          * Writing(Korean) - https://brunch.co.kr/@njnamju  \n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Import Data for Training Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3469, 96)\n"
     ]
    }
   ],
   "source": [
    "dfDis = pd.read_csv('data/cooked/google-third-place-Boston_DistanceClosest.csv')\n",
    "dfDis = dfDis.iloc[:, 1:]\n",
    "\n",
    "dataSetDis = dfDis.to_numpy()\n",
    "np.random.seed(222)\n",
    "np.random.shuffle(dataSetDis)\n",
    "X_dis = dataSetDis[:,:-1]\n",
    "y_dis = dataSetDis[:,-1:].flatten()\n",
    "\n",
    "dfDecay = pd.read_csv('data/cooked/google-third-place-Boston_DecayClosest.csv')\n",
    "dfDecay = dfDecay.iloc[:, 1:]\n",
    "print(dfDecay.shape)\n",
    "\n",
    "dataSetDecay = dfDecay.to_numpy()\n",
    "np.random.seed(222)\n",
    "np.random.shuffle(dataSetDecay)\n",
    "X_decay = dataSetDecay[:,:-1]\n",
    "y_decay = dataSetDecay[:,-1:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain_dis, XTest_dis, yTrain_dis, yTest_dis =train_test_split(X_dis, y_dis, test_size=0.2)\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(XTrain_dis)\n",
    "XTrainStd_dis = std_scale.transform(XTrain_dis)\n",
    "XTestStd_dis  = std_scale.transform(XTest_dis)\n",
    "\n",
    "XTrain_decay, XTest_decay, yTrain_decay, yTest_decay =train_test_split(X_decay, y_decay, test_size=0.2)\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(XTrain_decay)\n",
    "XTrainStd_decay = std_scale.transform(XTrain_decay)\n",
    "XTestStd_decay  = std_scale.transform(XTest_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hupbook/miniconda3/envs/nj-urban/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (91, 95)\n",
      "coef: [[-1.32411475e+01  7.57703712e-01 -2.59036866e-02 ... -1.56072965e+00\n",
      "  -2.13278052e-01 -1.44002624e-02]\n",
      " [ 3.82441585e-01 -1.71826356e+01  1.15993230e+00 ...  5.65947876e-01\n",
      "   2.34931714e+00  1.22438197e+00]\n",
      " [-3.05695358e-01  7.64177111e-01 -2.19415500e+01 ...  2.66048982e+00\n",
      "  -4.69749726e-01  1.96430793e-01]\n",
      " ...\n",
      " [-5.87175850e-01  4.61001643e-01 -2.44034053e+00 ...  1.65491487e+00\n",
      "   1.67030004e+00  4.55746189e-01]\n",
      " [ 1.19336930e+00 -5.21809273e-01  1.71542581e+00 ... -2.25651226e+01\n",
      "   4.52193229e-01  5.27824957e-01]\n",
      " [ 7.35577838e-01  2.06335330e+00  2.65331724e+00 ...  1.60352788e+00\n",
      "  -2.07277408e+01  1.44722850e+00]]\n",
      "intercept: [ -1.28184336  -7.95289461   2.63916357  -8.00499193  -7.21750992\n",
      "   6.50418693  -3.17949266   5.62544234   9.43204453  -5.70024025\n",
      "  -7.26831324   9.90541219  -7.83384252   1.66383876  -7.04661904\n",
      "  -6.38231345   8.8890572    4.52650148  -2.38835222  -7.8380407\n",
      "  -7.54936526  -2.10840798 -11.14215921  -8.08211468   7.61184948\n",
      "   7.39712591   7.27766177  -4.84778468  -7.83337785  -6.44005738\n",
      "   4.43483549  -4.25199074  -0.97726504  -2.88073644   3.57179569\n",
      "   9.57352501  -5.22595263   8.71537894  -7.26860546  10.03839789\n",
      "  -3.964109     8.96946292  -7.4678766   -5.67606441   4.47400691\n",
      "  -6.15087271   1.4772129   10.96862251   4.4323092   -3.42578446\n",
      "   5.45011787  -7.83460943  -7.83712958   1.48740883  -6.98404109\n",
      "  -3.93588597  -6.62826332   3.389416    -7.32025202  10.37553384\n",
      "  -7.33903656   5.66796135  -7.83475104   9.11476228  -7.47301734\n",
      "   4.44701031   1.46508081   8.82118773  11.14487889  -7.83427998\n",
      "   4.65904097   3.64252825  -2.21659045  -4.58206281   0.87355559\n",
      "   4.61179659   2.89162697  -4.83381902   8.11273984   3.29872755\n",
      "   5.57716909   8.57967791  -7.83704075   7.98037814 -10.60597652\n",
      "   7.52883952   6.51705718  -5.21613051   7.46196654   8.80246671\n",
      "  -6.32889555]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hupbook/miniconda3/envs/nj-urban/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrL2_dis =  LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='none', random_state=2)\n",
    "lrL2_dis.fit(XTrainStd_dis, yTrain_dis)\n",
    "\n",
    "print('shape: ', lrL2_dis.coef_.shape)\n",
    "print('coef:', lrL2_dis.coef_)\n",
    "print('intercept:', lrL2_dis.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hupbook/miniconda3/envs/nj-urban/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (92, 95)\n",
      "coef: [[ 2.94646768e+01 -1.05107797e-01 -2.66165017e-01 ...  1.15630653e+00\n",
      "  -2.36679952e-01 -3.48038025e-02]\n",
      " [-1.82446245e-01  1.70492131e+01 -1.05872455e-01 ... -4.65014160e-01\n",
      "  -9.39785204e-02  4.14466614e-02]\n",
      " [-1.29772508e-01  1.03485634e-04  1.60287995e+01 ... -3.47181228e-01\n",
      "  -8.17445054e-02  4.78175089e-02]\n",
      " ...\n",
      " [-4.72705743e-01 -7.94256709e-01 -1.35285680e+00 ...  5.61897958e+01\n",
      "  -1.24963960e+00 -4.67645837e-01]\n",
      " [-1.78887250e-01  3.34717242e-03 -9.56141082e-02 ... -2.47793094e-01\n",
      "   1.76869885e+01  4.06531299e-02]\n",
      " [ 1.17454071e-01  1.25299666e-01  1.14361829e-01 ...  8.59986396e-02\n",
      "   8.03182088e-02  1.19982127e+00]]\n",
      "intercept: [-1.12022397 -2.53920037 -2.65727951 -2.14107685 -3.74000614  1.1633107\n",
      " -1.52161569  8.63214284  5.17907117 -2.85297379 -3.55268365  3.02466449\n",
      " -3.75238647 -1.9657463  -2.00206364  6.39731289  0.91196226 -0.73495297\n",
      "  7.50136589 -3.711056   -2.87526989  3.45276971  5.878756   -0.14813796\n",
      "  6.26452644  7.00969624 -1.89196244 -3.75241209 -3.66633214  3.00617061\n",
      " -1.81766322 -2.70771733 -2.06707619 -2.2629785   0.10844019 -2.50783061\n",
      " -0.32930671 -3.73736204  1.37070373 -2.52240775  2.59378424 -3.76925166\n",
      "  7.64567892 -1.35400202 -2.81251778 -2.09754896  5.49940624 -1.44303642\n",
      "  3.63918942  7.59021362 -3.75233485 -3.7523427   8.83172568  6.94113006\n",
      " -3.13512022 -2.77997767  3.77868699 -3.34936831  0.80028423 -3.68820442\n",
      " -1.685716   -3.75236198 -0.4319328  -3.67548904 -2.29841504 -1.44376714\n",
      "  0.22895519  2.26053362 -3.75243505  6.37338589 -1.09937903 -3.0755387\n",
      " -3.63460722 -0.89139921 -1.29543679 -2.11841426 -1.61382792  1.16242127\n",
      " -3.79712033  3.24677552  0.21807704  3.81922854 -3.7524036   0.10812141\n",
      " -2.98574598  6.20577444  0.04072687 -2.11698976  6.39274743  6.93127059\n",
      " -2.52424062 -3.75236267]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hupbook/miniconda3/envs/nj-urban/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lrL2_decay =  LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='none', random_state=2)\n",
    "lrL2_decay.fit(XTrainStd_decay, yTrain_decay)\n",
    "\n",
    "print('shape: ', lrL2_decay.coef_.shape)\n",
    "print('coef:', lrL2_decay.coef_)\n",
    "print('intercept:', lrL2_decay.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13. 82. 77. 30.  3. 68. 92. 64. 23. 25. 79. 88. 35. 69. 34. 16. 75. 23.\n",
      " 44. 92. 68. 80.  2. 66. 25. 14. 80. 48. 48. 82. 41. 42. 48. 25. 17. 22.\n",
      " 23. 22. 31. 11. 88. 62. 60. 78. 75. 90.  2. 23. 26. 92. 23. 60. 17. 30.\n",
      " 82.  3. 22.  8. 28. 30. 58. 30. 80. 71. 82. 92. 89. 48.  7. 44. 87. 26.\n",
      " 15.  9. 50. 83. 58. 15. 33. 21. 78. 31.  8. 18.  7. 16. 80. 92. 24. 18.\n",
      " 88.  9. 18. 50. 66. 84. 48. 67.  8. 23. 18. 18. 64. 58. 51. 44. 23.  9.\n",
      " 88. 58. 32. 88. 54. 42. 82. 27. 91.  5. 66. 72. 54. 51. 75. 26. 75. 34.\n",
      " 74. 69. 33. 17. 33. 58. 35. 23. 23. 22. 32. 54. 88. 13. 18. 44. 30. 82.\n",
      " 92. 41. 75. 58. 49. 48. 62. 83. 49.  7. 15. 22. 75. 16. 37. 84. 23. 22.\n",
      " 88. 84. 89. 64. 88. 48. 80. 18. 89. 78.  2. 71. 26. 45. 46. 23. 62. 67.\n",
      " 80. 54. 44. 33. 90. 51. 42. 92. 88.  5. 17.  8. 45. 15.  5. 42. 82. 33.\n",
      " 50. 92. 27. 37.  8. 74. 62.  8. 45. 88. 62. 60. 68. 15. 18. 11. 17. 33.\n",
      " 54. 25.  3. 49. 21. 58.  8. 11. 22. 13. 89. 30. 82. 44. 23. 87.  9. 62.\n",
      " 83. 71. 55. 26. 82. 16. 16. 18. 44.  0. 17. 91.  8.  2. 80. 33. 49. 86.\n",
      " 78. 15. 83. 78. 25. 28. 30. 83. 48. 41. 15. 80. 91. 51. 51. 51. 64. 37.\n",
      " 77. 45. 51. 15. 82. 37. 40. 26. 82. 30. 88. 69. 54.  3. 18. 62.  8. 50.\n",
      " 92. 88. 22. 48. 64. 82.  0. 22.  8. 32. 16. 15. 31. 44.  8. 93. 22. 49.\n",
      " 54. 50. 89. 34. 25. 15.  1. 26. 77. 82. 69. 23. 58. 90. 54. 23. 88. 88.\n",
      " 77. 46. 14. 91. 36. 30. 28. 48. 88. 66. 71.  9. 83. 84. 37. 22. 86.  5.\n",
      " 71. 92.  6. 60. 64. 54. 25. 15. 23. 78.  9. 16. 60. 71. 44. 87. 92. 82.\n",
      " 72. 22. 77. 92. 92. 80. 48. 79. 49. 46. 91. 71. 26. 26.  7. 48. 80. 58.\n",
      " 71. 14. 14. 48. 15.  7. 91.  9. 35. 86. 50. 23. 34. 22. 92. 30. 50. 84.\n",
      " 15. 66. 71. 71. 64. 40.  2. 26. 17. 60. 18. 11. 75. 89.  9. 80.  9. 88.\n",
      " 58. 37. 50. 22. 45. 54. 44. 18. 48. 40. 51. 33. 30. 92. 16. 26. 66.  1.\n",
      "  7. 88. 11. 88. 33. 91.  0. 17. 48. 23. 34. 15.  0. 67. 84. 24. 17. 18.\n",
      " 77. 82. 64. 26. 26. 62.  9. 88. 77. 24. 48. 67. 48. 54.  8. 56. 89. 23.\n",
      " 56. 66. 18. 87. 22. 40. 75. 23. 71. 82. 45.  2. 51. 22. 18. 89. 44. 15.\n",
      " 23. 50. 50. 68. 82. 92. 48. 50. 25. 69. 80. 62.  8. 23. 11. 66. 16. 66.\n",
      " 88. 58. 46. 71. 71. 88. 45. 50.  1. 71. 14. 75. 16. 44. 58. 60. 26. 31.\n",
      "  8. 80. 62. 44. 92. 67. 25. 58. 92. 92. 62. 89. 40. 13. 71. 22. 67.  3.\n",
      " 22. 54. 62. 69. 23. 40. 82. 34. 66. 40.  8. 55. 82. 22. 51. 11. 69. 15.\n",
      " 37. 62.  8. 23. 18. 69. 45. 17. 60. 49. 54. 75. 87.  8. 15. 48. 18. 46.\n",
      " 71. 31. 92. 44. 58. 89. 17. 35. 58. 26. 42. 23. 33. 88. 46. 23. 45. 49.\n",
      " 50. 22. 32. 77. 58. 32. 58. 54. 82. 26. 22. 88. 23. 15. 33. 22. 18. 35.\n",
      " 89.  7.  7. 38. 92. 88. 33. 51. 40.  5. 27. 30. 45. 37. 91. 67. 77. 23.\n",
      " 24. 88. 91. 22. 23. 11. 45. 22. 18. 15. 22. 44. 90. 54. 71. 37. 78. 23.\n",
      "  1. 60.  9. 25. 45. 93.  8. 80. 34. 71. 16. 49. 32. 18. 84. 30. 92. 18.\n",
      " 88. 11. 77.  2. 80. 16. 64. 35. 30. 88. 87. 60. 68.  2. 64. 23.  2. 68.\n",
      " 45. 92. 45. 84.  7. 51. 17. 37. 15. 58.]\n",
      "0.29971181556195964\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred_logistic_dis = lrL2_dis.predict(XTestStd_dis)\n",
    "print(pred_logistic_dis)\n",
    "print(precision_score(yTest_dis, pred_logistic_dis,  average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37. 13. 58. 50. 35. 87. 80. 40.  7. 26.  2. 23. 80. 37. 58. 23. 29. 54.\n",
      "  6. 71. 68. 18. 26. 44. 74. 90. 22. 55. 72. 23. 35. 18. 49. 25.  6. 23.\n",
      " 62. 88. 48. 54. 89. 91. 30. 44. 34. 42. 51. 42. 30. 50. 62. 24. 18. 88.\n",
      " 44. 91. 83. 83.  2. 54. 35. 40. 73. 13. 51. 44. 60. 75. 26. 51. 62. 68.\n",
      " 78. 26. 91. 49. 55. 16. 32. 26. 26. 69. 58. 64. 25. 69.  9. 82. 24. 91.\n",
      " 78.  7. 60. 78. 68. 42. 48. 54. 15. 73. 48. 80. 86. 23. 69. 23. 89. 51.\n",
      " 22. 18. 51. 80. 49. 83.  8. 22. 40. 37. 25. 58. 51. 80. 46. 42. 22. 55.\n",
      " 44. 25. 40. 71. 18. 24. 60. 55. 92. 58. 30. 15. 82. 31. 84. 71.  7. 16.\n",
      " 45. 91. 25. 58. 11. 24.  8. 71. 92. 16. 88. 88. 67. 71. 11. 22. 73. 16.\n",
      " 55. 71. 11. 69. 71. 51. 22. 64. 71.  9. 37. 62. 35. 82. 51. 34. 54.  3.\n",
      " 48. 75. 51. 33. 79. 84. 22. 22. 64. 16.  7. 11. 75. 86. 62. 80. 89. 15.\n",
      " 86.  2. 86. 55.  5. 82. 22. 35. 72. 25. 22. 23.  7. 17. 25.  4. 22. 13.\n",
      " 22. 91. 51. 60. 84. 24. 13. 84. 60. 22. 25. 40. 84. 54. 23. 16. 68.  7.\n",
      " 15. 54.  8. 23. 45. 25. 24. 60.  9.  5. 46. 50. 49. 34. 83. 22.  7. 14.\n",
      " 55. 18. 55. 27. 64. 51. 69. 91.  2. 44.  6. 66. 35. 42. 58. 26. 11. 37.\n",
      " 82. 37. 75. 52. 62. 51. 50. 80. 55.  5. 62. 69. 23. 67. 66. 86. 25. 34.\n",
      " 23. 34. 25. 15. 48. 40. 40. 22. 83. 72. 73. 78. 72. 71. 22. 58. 58. 11.\n",
      " 72. 82. 40. 17. 49. 11. 34. 50. 64. 22. 68. 84. 75.  2. 51. 54. 87. 69.\n",
      " 92. 42. 64. 86. 50. 22. 88. 48. 73. 89. 16. 80. 72. 11. 82. 92. 55. 64.\n",
      " 30. 62. 31. 73. 14. 44. 80. 32. 58. 48. 44. 47. 54. 84. 87.  9. 64. 64.\n",
      "  2. 44. 55. 88. 82. 58. 87. 54. 62. 89. 86. 50. 89. 54. 71. 18. 26. 88.\n",
      "  6. 26. 18. 51. 69. 52. 44. 93. 50. 92. 14. 90.  7. 91. 60.  0. 93.  8.\n",
      " 15.  8. 24. 18.  2. 55. 51. 77. 40. 40. 18. 31.  8. 51. 16. 48. 55. 55.\n",
      " 69. 44. 23. 44. 84. 91. 91. 51.  7. 52. 30. 58. 66. 40. 69. 15. 92. 73.\n",
      " 60. 60. 83.  7. 51. 46. 93. 49. 78. 49.  5. 84. 72. 18. 82. 50. 26. 46.\n",
      " 22. 48. 51. 26. 16. 58. 91. 54.  8. 72. 51.  7. 71. 78. 48. 30. 75. 37.\n",
      " 34. 18. 22. 80. 26. 15. 92. 72.  8. 37. 50. 13. 35. 23. 50. 35. 48. 48.\n",
      " 51. 79. 45.  8. 30. 64.  5. 51. 30. 88. 60. 55. 30. 56.  5. 71. 80. 72.\n",
      " 11. 60. 47. 58. 26. 64. 60. 31. 72. 44. 60. 25. 87. 69. 15. 18. 80. 48.\n",
      " 60. 69. 51. 18. 56.  0. 89. 30. 26. 25. 92. 92. 18. 80. 54. 23. 89. 80.\n",
      " 13. 51. 18.  3. 23.  6. 14. 82. 32. 14.  7. 25. 60.  8. 35.  7. 62. 23.\n",
      " 24. 60. 18. 25. 84. 90. 21. 88. 69. 24. 67. 88. 16. 83. 77.  5. 55. 88.\n",
      " 54. 64. 15. 58. 54. 14. 22. 60.  7. 47. 16. 54. 45.  8. 45. 48. 26. 84.\n",
      " 89.  7. 69. 62. 26. 15. 71. 25. 77. 87. 55.  8.  2. 24. 54. 15. 13. 17.\n",
      " 48. 68. 50. 11. 42.  3. 18. 48. 18. 35. 68. 92.  7. 42. 15. 37. 58.  8.\n",
      " 51. 72. 25. 64. 58. 84. 54. 14. 51. 92. 64. 22.  9. 79. 89. 13. 82. 55.\n",
      " 17. 34. 58. 51. 55. 30. 54.  6. 69. 48. 89. 16. 86. 91. 17. 42.  3.  7.\n",
      " 88. 89.  8. 18. 72. 89. 18. 18. 92.  2. 45. 82. 80. 55. 16. 15. 26. 14.\n",
      " 30.  8. 15. 25. 71. 46. 86. 23.  9. 40.]\n",
      "0.7881844380403458\n"
     ]
    }
   ],
   "source": [
    "pred_logistic_decay = lrL2_decay.predict(XTestStd_decay)\n",
    "print(pred_logistic_decay)\n",
    "print(precision_score(yTest_decay, pred_logistic_decay,  average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.83497727e-04 1.74092509e-32 8.76157224e-12 ... 3.14094341e-26\n",
      "  1.27128045e-23 1.05044761e-02]\n",
      " [2.79147395e-04 7.44537953e-10 4.39501608e-13 ... 2.43322401e-06\n",
      "  6.46736880e-04 2.67427419e-17]\n",
      " [1.22587635e-03 1.26088734e-15 1.41344449e-16 ... 6.93012852e-06\n",
      "  2.64041868e-03 8.14101395e-11]\n",
      " ...\n",
      " [6.11697364e-06 5.15318727e-11 6.77978246e-09 ... 1.11249561e-04\n",
      "  2.06070078e-04 7.73029349e-21]\n",
      " [2.70291339e-02 1.62932600e-11 1.04804674e-10 ... 4.03149744e-02\n",
      "  6.13075879e-02 3.54743019e-25]\n",
      " [5.36662939e-21 1.20717157e-14 6.58115534e-19 ... 3.10156374e-02\n",
      "  2.21330262e-06 4.86039661e-14]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 6 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(lrL2_dis.predict_proba(XTestStd_dis))\n",
    "print(confusion_matrix(yTest_dis, pred_logistic_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.56706957e-090 8.74152090e-089 4.22812993e-088 ... 1.36073469e-098\n",
      "  9.83407137e-089 1.70017461e-089]\n",
      " [3.40793875e-103 2.50218297e-106 9.49125399e-129 ... 1.10259654e-086\n",
      "  1.30388602e-106 6.03406179e-107]\n",
      " [1.23703521e-097 7.29425187e-096 3.34164307e-094 ... 6.21402352e-104\n",
      "  6.52261568e-096 2.31102782e-097]\n",
      " ...\n",
      " [5.18986026e-095 5.45453430e-092 3.35727863e-095 ... 1.24240732e-092\n",
      "  1.30205658e-091 3.55250232e-087]\n",
      " [2.22550464e-082 3.00704270e-083 9.70829167e-083 ... 2.55330483e-090\n",
      "  6.67935583e-084 4.60314164e-087]\n",
      " [1.78827807e-002 1.20852590e-092 1.99020487e-090 ... 6.75717374e-100\n",
      "  6.38250104e-092 5.07855596e-091]]\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 9 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 9 0 0]\n",
      " [0 0 0 ... 0 9 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "print(lrL2_decay.predict_proba(XTestStd_decay))\n",
    "print(confusion_matrix(yTest_decay, pred_logistic_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.56706957e-090, 8.74152090e-089, 4.22812993e-088, 8.21903743e-089,\n",
       "       5.05884877e-089, 1.73506426e-092, 2.13207067e-092, 1.03102386e-068,\n",
       "       3.76011663e-094, 2.82275189e-089, 4.20891817e-090, 9.49178277e-066,\n",
       "       1.70050359e-089, 1.13689262e-089, 5.99965222e-088, 2.96350053e-083,\n",
       "       6.01719511e-089, 1.52901679e-090, 4.73094739e-053, 1.75251475e-089,\n",
       "       2.25228981e-089, 5.24763416e-089, 1.50039456e-107, 1.31043858e-089,\n",
       "       3.84659326e-101, 4.02850778e-111, 8.33992744e-089, 1.70085797e-089,\n",
       "       1.30915765e-089, 4.30495367e-090, 1.12046619e-089, 3.93604751e-089,\n",
       "       7.42583774e-087, 2.23212311e-089, 2.48787319e-090, 2.47697474e-089,\n",
       "       1.00000000e+000, 3.25000666e-089, 1.71357042e-093, 2.28535704e-083,\n",
       "       5.23465219e-090, 5.09819199e-066, 5.95594792e-104, 2.93071607e-087,\n",
       "       5.58569550e-089, 1.04815090e-088, 1.67698568e-042, 4.37364078e-090,\n",
       "       4.93848740e-090, 1.10218872e-094, 1.69979009e-089, 1.69989866e-089,\n",
       "       2.89665978e-100, 5.93997931e-096, 8.43626731e-088, 4.10929013e-081,\n",
       "       1.10019502e-098, 7.65515232e-088, 5.69324331e-092, 3.00955055e-089,\n",
       "       2.70310855e-090, 1.70016509e-089, 4.32816410e-093, 1.37701583e-089,\n",
       "       1.44533102e-088, 1.80924186e-088, 3.89436726e-090, 2.18214832e-072,\n",
       "       1.70117544e-089, 3.75114376e-094, 2.23058597e-083, 2.65153975e-088,\n",
       "       1.56114232e-089, 6.62292012e-089, 3.24177012e-089, 2.90572244e-088,\n",
       "       3.80107469e-092, 9.41547225e-065, 2.92080425e-089, 3.73808069e-083,\n",
       "       2.16297838e-087, 6.47410481e-096, 1.70074056e-089, 2.09980122e-092,\n",
       "       9.53173532e-089, 1.36267263e-100, 4.92663957e-068, 5.11714035e-090,\n",
       "       8.55729739e-093, 1.36073469e-098, 9.83407137e-089, 1.70017461e-089])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = lrL2_decay.predict_proba(XTestStd_decay)[0]\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn import svm \n",
    "\n",
    "lrSVM_dis = svm.SVC(kernel='linear', random_state=2)\n",
    "lrSVM_dis.fit(XTrainStd_dis, yTrain_dis)\n",
    "\n",
    "lrSVM_decay = svm.SVC(kernel='linear', random_state=2)\n",
    "lrSVM_decay.fit(XTrainStd_decay, yTrain_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93. 82. 27. 58. 87. 51. 91.  0. 23. 25. 27. 45. 17. 50.  7. 42. 75. 23.\n",
      " 44. 80.  6. 80. 48. 55. 16. 58. 80. 24. 17. 45.  2. 68. 58. 25. 30. 22.\n",
      " 23. 22. 31. 11. 88. 34. 23. 78. 75. 24. 80. 23. 16.  8. 22. 60. 17. 23.\n",
      " 42.  3. 22.  8. 85. 30.  7.  0. 30.  8. 82. 91. 68. 23. 82. 18. 87. 54.\n",
      " 15.  9. 31. 83. 82. 51. 89. 11. 78. 31.  8. 22. 30. 30. 58. 80. 40. 22.\n",
      " 88. 88. 15. 31. 18. 84. 89. 82.  8. 23. 18. 22. 23. 37. 54. 18. 23.  8.\n",
      " 51. 51. 32.  7. 54. 42. 15. 27. 91. 25. 55. 72.  8. 88. 88. 50. 75. 35.\n",
      " 35. 17.  5. 17. 16. 51. 82. 23. 23. 55. 68. 25. 88. 45. 18. 58. 15. 15.\n",
      " 23. 68. 60. 15. 49. 48. 62. 18. 90. 11. 15. 44. 89. 30.  6. 48. 23. 22.\n",
      " 88. 68. 88. 64. 88. 83. 80. 22. 58. 16. 82. 88. 26. 60.  0. 23.  2. 67.\n",
      " 51. 18. 44. 33. 90. 51. 91. 88. 88. 25. 91.  8. 45. 15. 49. 42. 82. 30.\n",
      " 31. 92.  0. 37. 91. 35. 18. 58. 14. 88. 62. 23. 26. 51. 18. 25. 60. 77.\n",
      " 22. 25.  3. 49. 32. 58.  8. 30. 55. 91. 89. 30. 82. 18. 23.  8.  9. 48.\n",
      " 51. 88. 18. 23. 82. 16. 16. 25. 15. 40. 91. 82.  8.  2. 47. 30. 13.  8.\n",
      " 78. 22. 18. 78. 25. 85. 22. 83. 25. 66. 23. 18. 91. 88.  7. 51. 15. 23.\n",
      " 64. 45. 51. 22. 82. 13. 35. 17. 35. 82. 88.  5. 25.  3. 25. 62.  8. 15.\n",
      " 92. 51. 22.  8. 64. 54.  0. 55.  8. 68. 16. 15. 31. 18.  8. 93. 22. 62.\n",
      " 54. 50. 89. 35. 25. 15.  1. 75. 80. 51.  7. 23. 58. 62. 51. 23. 88. 88.\n",
      " 77.  0. 14. 54. 36. 54. 85. 48.  7. 66. 77. 64. 30. 72. 37. 22. 24.  8.\n",
      " 25. 44.  6. 80. 64. 54. 25. 44. 23. 77.  9. 51. 31. 51. 18. 87. 23. 15.\n",
      " 75. 22. 77. 23. 80. 44. 25. 72. 13. 89. 91.  8. 26. 51.  7. 25. 80. 58.\n",
      " 62. 14. 14.  7. 15. 30. 91.  9.  5. 17. 22. 23. 88. 22.  8. 30. 91. 34.\n",
      " 15. 80. 58. 88. 51. 40.  2. 26. 17. 60. 22. 11. 72. 88. 88. 80. 71. 88.\n",
      " 15. 37. 22. 22. 45. 25. 18. 22. 58. 42. 51. 30. 54. 92. 16. 17. 18.  1.\n",
      " 54. 88. 11. 51. 89.  8.  0. 67. 58. 23.  7. 15.  0. 92. 72. 37. 17. 18.\n",
      " 72. 51. 64. 26. 22. 48.  9.  7. 77. 48.  7. 67. 26.  8.  8. 77. 89. 22.\n",
      " 56. 25. 18. 87. 15. 40. 75. 23. 88. 82. 46. 55.  5. 44. 25. 44. 58. 15.\n",
      " 22. 23. 31. 17. 82. 15. 45. 22. 82. 58. 51. 89.  8. 23. 25. 55. 69. 66.\n",
      " 51. 42. 75. 88. 88. 35. 45. 50.  1. 88. 14.  8. 51. 15. 58. 24. 23. 31.\n",
      " 91. 58. 47. 58. 91. 14. 58. 58. 64. 88. 82. 58. 40. 13. 55. 22. 92.  3.\n",
      " 22. 91. 18. 17. 23. 48. 82. 35. 55. 89. 48. 18. 23. 22.  7. 11. 69. 22.\n",
      " 54. 62.  8. 23. 25. 51. 46. 69. 78. 25.  8. 75. 87.  8. 22. 23. 18. 46.\n",
      " 78. 91. 49. 18. 18. 89. 17. 17. 17. 23. 42. 23. 33. 88. 46. 23. 45.  6.\n",
      " 55. 22.  8. 16. 15. 26. 64. 25. 82. 23. 55. 51. 23. 22. 30. 22. 15. 16.\n",
      " 89. 30.  7. 72. 91. 82. 33. 51. 40. 25. 68. 58. 82. 11. 25. 91. 77. 22.\n",
      " 24. 88. 91. 22. 22.  8. 45. 22. 22. 51. 22. 44. 90. 54. 88.  6. 37. 23.\n",
      "  1. 78.  9. 11. 46. 93. 25. 44.  2. 30. 69.  7. 77. 18. 84. 22. 23. 58.\n",
      " 88. 42. 86.  2. 18. 16. 80.  7. 80. 30. 87. 60. 68.  2. 64. 22.  2. 68.\n",
      " 14. 16. 45. 72. 58. 88. 17. 50. 15. 42.]\n",
      "0.15417867435158503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predSVM_dis = lrSVM_dis.predict(XTestStd_dis)\n",
    "print(predSVM_dis)\n",
    "print(accuracy_score(yTest_dis, predSVM_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37. 13. 58. 50. 35. 87. 80. 40.  7. 26.  2. 23. 80. 37. 58. 72. 29. 54.\n",
      "  6. 71. 68.  8. 26. 44. 74. 37. 22. 55. 72. 30. 35. 18. 49. 25.  6. 55.\n",
      " 62. 40. 44. 54. 89. 51. 30. 44. 34. 42. 88. 42. 30. 50. 62. 24. 18. 88.\n",
      " 44. 91. 83. 88.  2. 54. 35. 40. 73. 13. 15. 44. 60. 11. 26. 51. 62. 68.\n",
      " 78. 23. 91. 49.  8. 16. 32. 26. 26. 15. 58. 64. 25. 69.  9. 82. 24. 91.\n",
      " 78.  7. 60. 78. 68. 42. 48. 54. 15. 73. 48. 80. 86. 23. 69. 23. 89. 35.\n",
      " 22. 69. 51. 80. 49. 83.  8. 22. 40. 37. 48. 37. 48. 80. 46. 42. 22. 55.\n",
      " 44. 25. 40. 71. 18. 24. 60. 78. 92. 58. 30. 15. 82. 31. 84. 71.  7. 16.\n",
      " 45. 91. 25. 58. 11. 24. 71.  6. 92. 16. 23. 88. 67. 71. 11. 22. 73. 16.\n",
      " 54. 71. 11. 69. 71.  8. 22. 64. 25.  9. 37. 62. 35. 82. 88. 34. 54.  3.\n",
      " 48. 75. 51. 33. 79. 84. 22. 44. 64. 16.  7. 11. 75. 42. 62. 80. 89. 15.\n",
      " 86.  2. 86. 55.  5. 82. 22. 35. 72. 25. 22. 23. 23. 17. 25.  4. 22. 13.\n",
      " 22. 91. 51. 60. 84. 24. 13. 51. 60. 22. 25. 40. 84. 54. 23. 16. 68.  7.\n",
      " 15. 54.  8. 23. 45. 25. 24. 60.  9.  5. 46. 44. 49. 34. 83. 22.  8. 14.\n",
      " 55. 18. 18. 27. 64. 51. 69. 91.  2. 44.  6. 46. 35. 42. 58. 26. 11. 37.\n",
      " 82. 37. 60. 94. 69.  4. 50. 80. 55.  5. 62. 69. 23. 67. 66. 86.  6. 34.\n",
      " 23. 34. 25. 15. 48. 40. 40. 22. 83. 72. 73. 78. 72. 71. 22. 58. 58. 11.\n",
      " 72. 82. 26. 17. 49. 11. 34. 50. 64. 22. 68. 51. 75.  2. 51. 55. 87. 69.\n",
      " 92. 42. 22. 86. 50. 22. 88. 37. 73. 89. 16. 80. 72. 11. 58. 92. 23. 64.\n",
      " 30. 62. 31. 73. 14. 44. 80. 32. 58. 48. 44. 47. 54. 84. 87.  9. 64. 64.\n",
      "  2. 89. 55. 88. 82. 58. 87. 54. 62. 89. 86. 50. 89. 54. 71. 18. 26. 88.\n",
      "  6. 26. 18. 51. 69. 94. 44. 93. 50. 68. 14. 90.  7. 91. 18.  0. 93.  8.\n",
      " 26.  8. 24. 18.  2. 23. 51. 77. 40. 40. 18. 31.  8. 80. 16. 11. 55. 18.\n",
      " 84. 44. 23. 44. 84. 91. 91. 88.  7. 94. 30. 58. 66. 40. 69. 15. 92. 73.\n",
      " 60. 60. 83.  7. 51. 46. 11. 49. 58. 49.  5. 84. 72. 18. 82. 50. 26. 46.\n",
      " 44. 11. 51. 26. 35. 58. 91. 44.  8. 72. 51.  7. 71. 78. 48. 30. 75. 37.\n",
      " 34. 18. 22. 80. 23. 15. 72. 72.  8. 37. 50. 13. 35. 23. 82. 35. 48. 11.\n",
      " 80. 79. 45.  8. 30. 64.  5. 37. 30. 91. 60. 55. 30. 56. 92. 71. 80. 72.\n",
      " 11. 60. 47. 58. 26. 64. 60. 31. 72. 15. 60. 25. 87. 69. 15. 18. 35. 48.\n",
      " 60. 69. 51. 18. 56.  0. 89. 30. 26. 25. 92. 92. 18. 80. 54. 23. 89. 80.\n",
      " 13. 71. 15.  3. 23.  6. 14. 82. 32. 14.  7. 25. 60.  8. 35. 23. 62. 23.\n",
      " 24. 60. 18. 64. 15. 90. 21. 88. 69. 24. 67. 71. 16. 83. 77. 18. 55. 26.\n",
      " 44. 64. 15. 58. 54. 14. 44. 60.  7. 47. 16. 54. 45.  8. 45. 48. 26. 17.\n",
      " 89. 15. 69. 62. 26. 55. 71. 25. 77. 87. 78.  8.  2. 24. 54. 15. 13. 17.\n",
      " 75. 68. 50. 11. 42.  3. 18. 48. 18. 35. 68. 23.  7. 42. 72. 37. 58.  8.\n",
      " 51. 72. 25. 64. 44. 88. 15. 14. 51. 93. 64. 22.  9. 79. 89. 13. 82. 78.\n",
      " 17. 34. 58. 51. 23. 30. 54.  6. 69. 48. 89. 16. 86. 91. 17. 42.  3.  7.\n",
      " 88. 89.  8.  7. 72. 89. 18. 18. 92.  2. 45. 82. 80. 55. 16. 15. 26. 14.\n",
      " 30. 89. 15. 25. 71. 46. 86. 55.  9. 49.]\n",
      "0.6974063400576369\n"
     ]
    }
   ],
   "source": [
    "predSVM_decay = lrSVM_decay.predict(XTestStd_decay)\n",
    "print(predSVM_decay)\n",
    "print(accuracy_score(yTest_decay, predSVM_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 3 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yTest_dis, predSVM_dis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### References & Useful links\n",
    "\n",
    "Lee, N. (2021). Understanding and Analyzing the Characteristics of the Third Place in Urban Design: A Methodology for Discrete and Continuous Data in Environmental Design. In: Yuan, P.F., Yao, J., Yan, C., Wang, X., Leach, N. (eds) Proceedings of the 2020 DigitalFUTURES. CDRF 2020. Springer, Singapore. https://doi.org/10.1007/978-981-33-4400-6_11\n",
    "\n",
    "\n",
    "\n",
    "Oldenburg, R., Brissett, (1982). D.: The third place. Qual. Sociol. 5(4), 265–284\n",
    "\n",
    "\n",
    "\n",
    "Lee, Namju. (2022). Computational Design, Seoul, Bookk, https://brunch.co.kr/@njnamju/144\n",
    "\n",
    "\n",
    "\n",
    "Lee, Namju, (2022). Discrete Urban Space and Connectivity, https://nj-namju.medium.com/discrete-urban-space-and-connectivity-492b3dbd0a81\n",
    "\n",
    "\n",
    "\n",
    "Woo. Junghyun, (2022). Numeric Network Analysis for Pedestrians, https://axuplatform.medium.com/0-numeric-network-analysis-47a2538e636c\n",
    "\n",
    "\n",
    "\n",
    "Lee, Namju, (2022). Computational Design Thinking for Designers, https://nj-namju.medium.com/computational-design-thinking-for-designers-68224bb07f5c\n",
    "\n",
    "\n",
    "\n",
    "Lee, Namju. (2016). Third Place Mobility Energy Consumption Per Person, http://www.njstudio.co.kr/main/project/2016_MobilityEnergyConsumptionMITMediaLab \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nj-urban",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
